{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\canbe\\Python Projects\\biobert-pytorch\\virtualenv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 629/629 [00:00<00:00, 624kB/s]\n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 255M/255M [00:11<00:00, 23.1MB/s] \n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48.0/48.0 [00:00<00:00, 47.5kB/s]\n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 226k/226k [00:00<00:00, 535kB/s]  \n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997795224189758},\n",
       " {'label': 'POSITIVE', 'score': 0.8319652080535889}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(['We are very happy to show you the ðŸ¤— Transformers library.', 'We hope you don\\'t hate it'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\canbe\\Python Projects\\biobert-pytorch\\virtualenv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline #doppelt\n",
    "speech_recognizer = pipeline('automatic-speech-recognition', model='facebook/wav2vec2-base-960h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset minds14 (C:\\Users\\canbe\\.cache\\huggingface\\datasets\\PolyAI___minds14\\en-US\\1.0.0\\ca170f4e2acf536108fbb62103a210428d54744476a461115e41d4b2b57b185f)\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "dataset = datasets.load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT'},\n",
       " {'text': \"FONDERING HOW I'D SET UP A JOIN TO HELL T WITH MY WIFE AND WHERE THE AP MIGHT BE\"},\n",
       " {'text': \"I I'D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I'M NOT SEEING THE OPTION TO DO IT ON THE APSO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AN I'M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS\"},\n",
       " {'text': 'HOW DO I FURN A JOINA COUT'},\n",
       " {'text': 'CAN NO YOU HELP ME STET UP AN JOINT LEAKACCOUNT'},\n",
       " {'text': \"HOW'TO FET UP TE JOINA COUT\"},\n",
       " {'text': 'I D LIKE YOU OPEN A JOINT A CAMP O TELL ME OF WHAT PRUSSUSES I THINK'},\n",
       " {'text': 'O CAN I HAVE AN ACCOUNT WITH ON MY SISTERS I WANT TO FELL UP A JOIN ACCOUNT'},\n",
       " {'text': 'A I NEED TO FIND OUT ABOUT HOW TO SET UP A JOINT A GENT PLESE'},\n",
       " {'text': 'I AM CALLING BECAUSE I WOULD LIKE TO SET UP AN ACCOUNT THAT IS JOINT WITH MY PARTNER IS THIS CLASSIBLE AND ADTHERE A JOINT ACOUNT THAT I CAN SEE ON THE HALF'},\n",
       " {'text': 'PLL YOUS LET ME HOPE CUTTING OUTTEY ANJOINAE TOWL'},\n",
       " {'text': 'HOW DO I GO ABOUT AS I DID NOT PAY JOIN TO COUNT FOR MY WIFE AND I'},\n",
       " {'text': 'Y I WAS TRYING TO SET UP A JOINT A COUNT IS THERE SOMEWHERE ON THE AT THAT I CAN DO THAT OR DO AD TO DO THAT THROUGH YOU'},\n",
       " {'text': 'I WAS WANTING TO SETT UP A JOINT ACCOUNT WITH MY SPOUSE AND I WAS WONDERING DO WE EACH GET A SUPPER CAR DUBET CARD AND ON A SEPARATE WAY OF KNOWING WHO IS EXCESSING THE ACCOUNT THANK YOU'},\n",
       " {'text': 'HOW DO I FEEL EVER JOIN A COUNT'},\n",
       " {'text': 'HA I WAS HOPING TO SET UP A JOIN A COUNT AN HE HELI TAT'},\n",
       " {'text': 'THE IDLA TREW O TE JOURNA PON'},\n",
       " {'text': 'NOT AWAY SET OFF A JOINT ACCOUNT'},\n",
       " {'text': 'HULLO HOW WOULD I GO ABOUT SETTING UP A JOINT ACCOUNT WITH MY PARTNER'},\n",
       " {'text': \"HULLO I'D LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I DO THAT\"},\n",
       " {'text': \"I AS I CASET AT BUT JOY A COW CAN'T I DO THAT IN THE AIR\"},\n",
       " {'text': 'HOW DO I GO ABOUT FICKING UP A JOINED THE COUNT WITH MY PARTNER AND EASISABAILABLE ON THE AP'},\n",
       " {'text': 'HOW CAN MY WIFE AND I SET UP IN JOINT ACCOUNT'},\n",
       " {'text': 'COULD YOU PLEASE TELL ME HOW TO SET UP A JOINT ACCOUNT'},\n",
       " {'text': 'I BI TO SET UP A JOINT ACCOUNT'},\n",
       " {'text': 'THEN I SET UP AND JOIN TO COUNT'},\n",
       " {'text': 'SET UP AJOIT ACCOUNT'},\n",
       " {'text': \"HOW'L I GO ABOUT SETTING UP A JOINT ACCOUNT FOR MY PARTNER AND MYSELF\"},\n",
       " {'text': \"AY I'M ON YOUR AP AND MY HUSBAND AND I ARE TRYING TO ST UP A JOIN TO COUNT I CAN SEE WHERE I SET UP AN ACCOUNT BY MYSELF BUT I'M NOT SURE WHERE TO GO TO SET UP A JOINT ACCOUNT CAN YOU HELP ME WITH IS PLEASE THANK YOU\"},\n",
       " {'text': 'HELLO THE GO  OPEN UP A JOINT TO COUNT WITH MY PARTNER I AM ALL JUST WONDERING HOW TO DO THAT'},\n",
       " {'text': 'HOW WOULD I SET UP A JOINT ACCOUNT FOR MYSELF AND MY PARTNER'},\n",
       " {'text': \"I'D LIKE INFORMATION ABOUT FINDING UT FOR A JOINT ACCOUNT\"},\n",
       " {'text': 'AY I WAS WONDERING HOW I OUD SET UP A JOINT ACCOUNT WITH MY PARTNER'},\n",
       " {'text': \"HELLO YES MY SON IS GOING OFF TO COLLEGE AND I'D LIKE TO SET UP A JOINT ACCOUNT SO THAT WE CAN BOT THE ACCESS ERTAIN WHAT FUNNY IN TO IT I THERE'S A RUN ANY MERGENCIES\"},\n",
       " {'text': \"YES I'M LIKE TO SUP A JOIN ACCOUNT AH I'M ALLOWED TO SU ADOIN A COW ANY ONE AND WHERE AN THE APAT THE OXOR FOR ME TO TOHO BRAJOIN ACCOUNT\"},\n",
       " {'text': 'HULLO I WAS JUST CALLING TO SEE IF I CAN MAKE A JOIN ACCOUNT WITH MY WIFE THANK YOU'},\n",
       " {'text': 'HOW DO I SET UP A JOIN A COUNT'},\n",
       " {'text': \"YES HALLO I AM CALLING IT BECAUSE I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY WIFE YES YES IT'S WITH MY PARTNER YEM O C I WILL SHOW UP TO YOUR BANK\"},\n",
       " {'text': 'I LIKE TO AS FOR MONE TO MY ACCOUNT CLIF'},\n",
       " {'text': 'AH NEED TO SET UP A JOINDE CONT'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = dataset['path']\n",
    "speech_recognizer(files[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 953/953 [00:00<00:00, 475kB/s]\n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 638M/638M [00:35<00:00, 19.0MB/s] \n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39.0/39.0 [00:00<00:00, 39.0kB/s]\n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 851k/851k [00:00<00:00, 1.26MB/s] \n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112/112 [00:00<00:00, 37.3kB/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '5 stars', 'score': 0.7272652983665466}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)\n",
    "classifier('Nous sommes trÃ¨s heureux de vous prÃ©senter la bibliothÃ¨que ðŸ¤— Transformers.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103, 100, 58263, 13299, 10110, 10103, 10675, 63727, 10103, 10103, 10103, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer('We are very happy to show you the ðŸ¤— Transformers library and the other stuff the the the'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103,   100,\n",
      "         58263, 13299,   119,   102],\n",
      "        [  101, 11312, 18763, 10855, 11530,   112,   162, 39487, 10197,   119,\n",
      "           102,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "pt_batch = tokenizer(\n",
    "    [\"We are very happy to show you the ðŸ¤— Transformers library.\", \"We hope you don't hate it.\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "print(pt_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_outputs = pt_model(**pt_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n",
      "        [0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)\n",
    "print(pt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_save_directory = \"./pt_save_pretrained\"\n",
    "tokenizer.save_pretrained(pt_save_directory)\n",
    "pt_model.save_pretrained(pt_save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_model = AutoModelForSequenceClassification.from_pretrained(\"./pt_save_pretrained\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "034f56ab372d2725712edfa684d3915454d80612e7053f2a79e439ef319be30d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('virtualenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
